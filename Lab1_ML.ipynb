{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9d1163ba",
      "metadata": {
        "id": "9d1163ba"
      },
      "source": [
        "# Lab 1: Machine Learning with Python using Scikit-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68162a36",
      "metadata": {
        "id": "68162a36"
      },
      "source": [
        "# Machine learning: the problem setting\n",
        "\n",
        "In machine learning, we usually have a bunch of data samples and we want to predict something about new, unseen data. Each data sample can have multiple pieces of information (like height, weight, age, etc.), which we call features. So, we use the data we have to learn how to make predictions about new data based on its features.\n",
        "\n",
        "-------------------------------------------------------------------------------------------------------------------\n",
        "Learning problems fall into a few categories:\n",
        "\n",
        "# supervised learning\n",
        "\n",
        "in which the data comes with additional attributes that we want to predict\n",
        "\n",
        "This problem can be either:\n",
        "\n",
        "classification: samples belong to two or more classes and we want to learn from already labeled data how to predict the class of unlabeled data. An example of a classification problem would be handwritten digit recognition, in which the aim is to assign each input vector to one of a finite number of discrete categories. Another way to think of classification is as a discrete (as opposed to continuous) form of supervised learning where one has a limited number of categories and for each of the n samples provided, one is to try to label them with the correct category or class.\n",
        "\n",
        "regression: if the desired output consists of one or more continuous variables, then the task is called regression. An example of a regression problem would be the prediction of the length of a salmon as a function of its age and weight.\n",
        "\n",
        "# unsupervised learning\n",
        "\n",
        "in which the training data consists of a set of input vectors x without any corresponding target values.\n",
        "\n",
        "The goal in such problems may be to discover groups of similar examples within the data, where it is called clustering, or to determine the distribution of data within the input space, known as density estimation, or to project the data from a high-dimensional space down to two or three dimensions for the purpose of visualization\n",
        "\n",
        "-------------------------------------------------------------------------------------------------------------------\n",
        "\n",
        "# Training set and testing set\n",
        "\n",
        "Machine learning is about learning some properties of a data set and then testing those properties against another data set. A common practice in machine learning is to evaluate an algorithm by splitting a data set into two. We call one of those sets the training set, on which we learn some properties; we call the other set the testing set, on which we test the learned properties."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58128433",
      "metadata": {
        "id": "58128433"
      },
      "source": [
        "#  Dataset loading utilities using Scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ccc165a6",
      "metadata": {
        "id": "ccc165a6"
      },
      "source": [
        "The sklearn.datasets package embeds some small toy datasets\n",
        "This package also features helpers to fetch larger datasets commonly used by the machine learning community to benchmark algorithms on data that comes from the ‘real world’.\n",
        "\n",
        "There are three main kinds of dataset interfaces that can be used to get datasets depending on the desired type of dataset.\n",
        "\n",
        "1. The dataset loaders: They can be used to load small standard datasets\n",
        "2. The dataset fetchers: They can be used to download and load larger datasets\n",
        "\n",
        "   Both loaders and fetchers functions return a Bunch object holding at least two items: an array of shape n_samples * n_features with key data and a numpy array of length n_samples, containing the target values, with key target.\n",
        "\n",
        "   The Bunch object is a dictionary that exposes its keys as attributes.\n",
        "\n",
        "   In scikit-learn datasets, each dataset comes with some additional information:\n",
        "\n",
        "      + DESCR Attribute: This is a description of the dataset. It provides details about where the data came from, how it was collected, and what each feature represents. It gives you a better understanding of the dataset.\n",
        "\n",
        "      + feature_names: For datasets where each data sample has multiple features, feature_names provides the names of these features. For example, in a dataset about iris flowers, feature_names might include \"sepal length,\" \"sepal width,\" \"petal length,\" and \"petal width.\"\n",
        "\n",
        "      + target_names: For datasets where you're trying to predict a specific category or value (like the species of an iris flower), target_names provides the names of these categories or values. For example, in the iris dataset, target_names might include \"setosa,\" \"versicolor,\" and \"virginica.\"\n",
        "\n",
        "3. The dataset generation functions: They can be used to generate controlled synthetic datasets\n",
        "\n",
        "\n",
        "![Screenshot%202024-02-14%20at%206.45.17%20AM.png](attachment:Screenshot%202024-02-14%20at%206.45.17%20AM.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db73beb5",
      "metadata": {
        "id": "db73beb5"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris, load_digits ,fetch_openml\n",
        "iris_data = load_iris()\n",
        "digits = load_digits()\n",
        "dating_data = fetch_openml(\"SpeedDating\", version=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8516e100",
      "metadata": {
        "id": "8516e100"
      },
      "source": [
        "A dataset is a dictionary-like object that holds all the data and some metadata about the data. This data is stored in the .data member, which is a n_samples, n_features array. In the case of supervised problems, one or more response variables are stored in the .target member."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf0f14fe",
      "metadata": {
        "id": "cf0f14fe",
        "outputId": "23fed53e-cb42-4c38-96a7-713278246691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.  0.  5. ...  0.  0.  0.]\n",
            " [ 0.  0.  0. ... 10.  0.  0.]\n",
            " [ 0.  0.  0. ... 16.  9.  0.]\n",
            " ...\n",
            " [ 0.  0.  1. ...  6.  0.  0.]\n",
            " [ 0.  0.  2. ... 12.  0.  0.]\n",
            " [ 0.  0. 10. ... 12.  1.  0.]]\n"
          ]
        }
      ],
      "source": [
        "print(digits.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72c4fb20",
      "metadata": {
        "id": "72c4fb20",
        "outputId": "156e1e8f-56c1-486e-8ae7-ee1847fd0fef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, ..., 8, 9, 8])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "digits.target"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "261852c7",
      "metadata": {
        "id": "261852c7"
      },
      "source": [
        "#  Shape of the data arrays\n",
        "\n",
        "The data is always a 2D array, shape (n_samples, n_features), although the original data may have had a different shape. In the case of the digits, each original sample is an image of shape (8, 8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8340fc6",
      "metadata": {
        "id": "d8340fc6",
        "outputId": "216ef7a8-3e7a-4fea-85a2-f474d2eb2b15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Keys of iris_dataset: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
            ".. _iris_dataset:\n",
            "\n",
            "Iris plants dataset\n",
            "--------------------\n",
            "\n",
            "**Data Set Characteristics:**\n",
            "\n",
            "    :Number of Instances: 150 (50 in each of three classes)\n",
            "    :Number of Attributes: 4 numeric, pre\n",
            "...\n"
          ]
        }
      ],
      "source": [
        "print(\"Keys of iris_dataset: {}\".format(iris_data.keys()))\n",
        "\n",
        "\n",
        "print(iris_data['DESCR'][:193] + \"\\n...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "862d14bf",
      "metadata": {
        "id": "862d14bf",
        "outputId": "20858500-99b4-45d0-c73e-80181bb8c9d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Targets: ['setosa' 'versicolor' 'virginica']\n",
            "Features: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "Shape of data: (150, 4)\n",
            "First 5 rows:\n",
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n",
            "Targets:\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n"
          ]
        }
      ],
      "source": [
        "print(\"Targets: {}\".format(iris_data['target_names']))\n",
        "print(\"Features: {}\".format(iris_data['feature_names']))\n",
        "print(\"Shape of data: {}\".format(iris_data['data'].shape))\n",
        "print(\"First 5 rows:\\n{}\".format(iris_data['data'][:5]))\n",
        "print(\"Targets:\\n{}\".format(iris_data['target']))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a4f0414",
      "metadata": {
        "id": "5a4f0414"
      },
      "source": [
        "# Loading from external datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7703ca9c",
      "metadata": {
        "id": "7703ca9c"
      },
      "source": [
        "scikit-learn works on any numeric data stored as numpy arrays or scipy sparse matrices. Other types that are convertible to numeric arrays such as pandas DataFrame are also acceptable.\n",
        "\n",
        "Here are some recommended ways to load standard columnar data into a format usable by scikit-learn:\n",
        "\n",
        "pandas.io provides tools to read data from common formats including CSV, Excel, JSON and SQL. DataFrames may also be constructed from lists of tuples or dicts. Pandas handles heterogeneous data smoothly and provides tools for manipulation and conversion into a numeric array suitable for scikit-learn.\n",
        "\n",
        "scipy.io specializes in binary formats often used in scientific computing context such as .mat and .arff\n",
        "\n",
        "numpy/routines.io for standard loading of columnar data into numpy arrays\n",
        "\n",
        "scikit-learn’s load_svmlight_file for the svmlight or libSVM sparse format\n",
        "\n",
        "scikit-learn’s load_files for directories of text files where the name of each directory is the name of each category and each file inside of each directory corresponds to one sample from that category\n",
        "\n",
        "For some miscellaneous data such as images, videos, and audio, you may wish to refer to:\n",
        "\n",
        "skimage.io or Imageio for loading images and videos into numpy arrays\n",
        "\n",
        "scipy.io.wavfile.read for reading WAV files into a numpy array\n",
        "\n",
        "Categorical (or nominal) features stored as strings (common in pandas DataFrames) will need converting to numerical features using OneHotEncoder or OrdinalEncoder or similar. S"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6bea9f60",
      "metadata": {
        "id": "6bea9f60"
      },
      "source": [
        "# LEARNINNG\n",
        "# Building models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4e1bec5",
      "metadata": {
        "id": "a4e1bec5"
      },
      "source": [
        "In the case of the digits dataset, the task is to predict, given an image, which digit it represents. We are given samples of each of the 10 possible classes (the digits zero through nine) on which we fit an estimator to be able to predict the classes to which unseen samples belong.\n",
        "\n",
        "In scikit-learn, an estimator for classification is a Python object that implements the methods fit(X, y) and predict(T).\n",
        "\\\n",
        "\n",
        "## All scikitlearn estimators follow the same interface\n",
        "\n",
        "class SupervisedEstimator(...):\n",
        "\n",
        "    def __init__(self, hyperparam, ...):\n",
        "\n",
        "    def fit(self, X, y):   # Fit/model the training data\n",
        "        ...                # given data X and targets y\n",
        "        return self\n",
        "     \n",
        "    def predict(self, X):  # Make predictions\n",
        "        ...                # on unseen data X  \n",
        "        return y_pred\n",
        "    \n",
        "    def score(self, X, y): # Predict and compare to true\n",
        "        ...                # labels y                \n",
        "        return score"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c38f2a6b",
      "metadata": {
        "id": "c38f2a6b"
      },
      "source": [
        "An example of an estimator is the class sklearn.svm.SVC, which implements support vector classification. The estimator’s constructor takes as arguments the model’s parameters.\n",
        "\n",
        "For now, we will consider the estimator as a black box:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5254b74f",
      "metadata": {
        "id": "5254b74f",
        "outputId": "30aeb601-2ae8-4ce3-c6f3-dfd540811fb6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([8])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "clf = svm.SVC(gamma=0.001, C=100.)\n",
        "\n",
        "clf.fit(digits.data[:-1], digits.target[:-1])\n",
        "clf.predict(digits.data[-1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88b06377",
      "metadata": {
        "id": "88b06377"
      },
      "source": [
        "The corresponding image is:\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "As you can see, it is a challenging task: after all, the images are of poor resolution. Do you agree with the classifier?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7a8b02b",
      "metadata": {
        "id": "c7a8b02b"
      },
      "source": [
        "# Training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e192fa0",
      "metadata": {
        "id": "1e192fa0",
        "outputId": "f0f4fc75-c89b-4e98-d25d-864630836d63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (112, 4)\n",
            "y_train shape: (112,)\n",
            "X_test shape: (38, 4)\n",
            "y_test shape: (38,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_data['data'], iris_data['target'], random_state=0)\n",
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "print(\"y_train shape: {}\".format(y_train.shape))\n",
        "print(\"X_test shape: {}\".format(X_test.shape))\n",
        "print(\"y_test shape: {}\".format(y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e6c6b03a",
      "metadata": {
        "id": "e6c6b03a",
        "outputId": "77f4fb45-97e3-4bba-b30e-7a2679ee9a02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Xs_train shape: (15, 4)\n",
            "Xs_test shape: (8, 4)\n"
          ]
        }
      ],
      "source": [
        "X, y = iris_data['data'], iris_data['target']\n",
        "Xs_train, Xs_test, ys_train, ys_test = train_test_split(X,y, stratify=y, train_size=0.1, test_size=0.05)\n",
        "print(\"Xs_train shape: {}\".format(Xs_train.shape))\n",
        "print(\"Xs_test shape: {}\".format(Xs_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02ec7422",
      "metadata": {
        "id": "02ec7422"
      },
      "source": [
        "# Fitting a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3fe4f3f6",
      "metadata": {
        "id": "3fe4f3f6",
        "outputId": "528f1a66-3579-4c78-c475-72f7e354d17a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KNeighborsClassifier(n_neighbors=1)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "knn.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5c55b8a",
      "metadata": {
        "id": "d5c55b8a"
      },
      "source": [
        "# Making predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dba8278b",
      "metadata": {
        "id": "dba8278b",
        "outputId": "2bd5be48-0b6a-40b7-fc19-ec7d410528d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction: [0]\n",
            "Predicted target name: ['setosa']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "X_new = np.array([[5, 2.9, 1, 0.2]])\n",
        "prediction = knn.predict(X_new)\n",
        "print(\"Prediction: {}\".format(prediction))\n",
        "print(\"Predicted target name: {}\".format(\n",
        "       iris_data['target_names'][prediction]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a858b236",
      "metadata": {
        "id": "a858b236"
      },
      "source": [
        "# Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1300f002",
      "metadata": {
        "id": "1300f002",
        "outputId": "86b20319-9218-443e-c7da-0b735663a415"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test set predictions:\n",
            " [2 1 0 2 0 2 0 1 1 1 2 1 1 1 1 0 1 1 0 0 2 1 0 0 2 0 0 1 1 0 2 1 0 2 2 1 0\n",
            " 2]\n"
          ]
        }
      ],
      "source": [
        "y_pred = knn.predict(X_test)\n",
        "print(\"Test set predictions:\\n {}\".format(y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3342a0c",
      "metadata": {
        "id": "a3342a0c",
        "outputId": "e0d695c3-782e-4b3e-bf20-bdcf7b4f9d68"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9736842105263158"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "knn.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "347636ae",
      "metadata": {
        "id": "347636ae",
        "outputId": "3a3b0a5b-9c19-48ab-fa80-aebdc66ec04d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score: 0.97\n"
          ]
        }
      ],
      "source": [
        "print(\"Score: {:.2f}\".format(knn.score(X_test, y_test) ))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}